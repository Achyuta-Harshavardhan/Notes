Cross Validation:
1. Leave One Out CV (LOOCV)---> (Low bias and high computation)
2. K fold CV
3. Stratified cross validation --> no of instance in each class is in proper proportion
4. Time series CV

Sensitiviry: TP/TP+FN 
Specificity: TN/TN+FP

Sensitivity need to be high if positive model prediction is important
Specificity need to be high if negative model prediction is important

Bias and Varience:
























Decision Tree:

yes/No:
1. Calculate the Gini impurity scores
2. if the node itself has the lowest score, then there is no point in seperating further and it becomes the leaf node
3. if seperating the data results in an improvement, then pick the seperation with the lowest impurity value

Numeric:
1. sort all the values in ascending order
2. calculate the average value for all the adjacent records
3. calculate the gini impurity for each of the average value

Ranked/Multiple choice:
1. If there are four ranks we need to calculate the gini impurity for rank 1,2 and 3.
2. for multiple choices we need to calculate giniimpurity for each one as well as each possible combination.

Gini impurity is used because it is computationally efficient

Random Forest:

